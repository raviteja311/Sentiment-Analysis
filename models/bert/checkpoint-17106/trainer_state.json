{
  "best_global_step": 5702,
  "best_metric": 0.7805747389723933,
  "best_model_checkpoint": "models/bert\\checkpoint-5702",
  "epoch": 3.0,
  "eval_steps": 500,
  "global_step": 17106,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.008768853034023149,
      "grad_norm": 9.269451141357422,
      "learning_rate": 1.9942710160177717e-05,
      "loss": 0.5719,
      "step": 50
    },
    {
      "epoch": 0.017537706068046298,
      "grad_norm": 4.063092231750488,
      "learning_rate": 1.9884251139950898e-05,
      "loss": 0.5096,
      "step": 100
    },
    {
      "epoch": 0.02630655910206945,
      "grad_norm": 14.730921745300293,
      "learning_rate": 1.9825792119724076e-05,
      "loss": 0.543,
      "step": 150
    },
    {
      "epoch": 0.035075412136092596,
      "grad_norm": 17.481151580810547,
      "learning_rate": 1.9767333099497254e-05,
      "loss": 0.5779,
      "step": 200
    },
    {
      "epoch": 0.04384426517011575,
      "grad_norm": 35.991416931152344,
      "learning_rate": 1.970887407927043e-05,
      "loss": 0.535,
      "step": 250
    },
    {
      "epoch": 0.0526131182041389,
      "grad_norm": 18.323360443115234,
      "learning_rate": 1.9650415059043612e-05,
      "loss": 0.5148,
      "step": 300
    },
    {
      "epoch": 0.061381971238162046,
      "grad_norm": 22.36538314819336,
      "learning_rate": 1.959195603881679e-05,
      "loss": 0.5384,
      "step": 350
    },
    {
      "epoch": 0.07015082427218519,
      "grad_norm": 9.89327335357666,
      "learning_rate": 1.953349701858997e-05,
      "loss": 0.6182,
      "step": 400
    },
    {
      "epoch": 0.07891967730620834,
      "grad_norm": 11.813533782958984,
      "learning_rate": 1.947503799836315e-05,
      "loss": 0.5684,
      "step": 450
    },
    {
      "epoch": 0.0876885303402315,
      "grad_norm": 11.302872657775879,
      "learning_rate": 1.941657897813633e-05,
      "loss": 0.4822,
      "step": 500
    },
    {
      "epoch": 0.09645738337425465,
      "grad_norm": 17.465103149414062,
      "learning_rate": 1.9358119957909508e-05,
      "loss": 0.5804,
      "step": 550
    },
    {
      "epoch": 0.1052262364082778,
      "grad_norm": 19.91106414794922,
      "learning_rate": 1.9299660937682686e-05,
      "loss": 0.4925,
      "step": 600
    },
    {
      "epoch": 0.11399508944230095,
      "grad_norm": 10.399276733398438,
      "learning_rate": 1.9241201917455864e-05,
      "loss": 0.5983,
      "step": 650
    },
    {
      "epoch": 0.12276394247632409,
      "grad_norm": 11.926600456237793,
      "learning_rate": 1.9182742897229045e-05,
      "loss": 0.5741,
      "step": 700
    },
    {
      "epoch": 0.13153279551034724,
      "grad_norm": 17.118207931518555,
      "learning_rate": 1.9124283877002222e-05,
      "loss": 0.5936,
      "step": 750
    },
    {
      "epoch": 0.14030164854437038,
      "grad_norm": 17.661211013793945,
      "learning_rate": 1.90658248567754e-05,
      "loss": 0.5892,
      "step": 800
    },
    {
      "epoch": 0.14907050157839355,
      "grad_norm": 19.39344596862793,
      "learning_rate": 1.900736583654858e-05,
      "loss": 0.5185,
      "step": 850
    },
    {
      "epoch": 0.1578393546124167,
      "grad_norm": 18.833372116088867,
      "learning_rate": 1.894890681632176e-05,
      "loss": 0.5458,
      "step": 900
    },
    {
      "epoch": 0.16660820764643985,
      "grad_norm": 11.862829208374023,
      "learning_rate": 1.889044779609494e-05,
      "loss": 0.5683,
      "step": 950
    },
    {
      "epoch": 0.175377060680463,
      "grad_norm": 12.708547592163086,
      "learning_rate": 1.8831988775868118e-05,
      "loss": 0.5946,
      "step": 1000
    },
    {
      "epoch": 0.18414591371448616,
      "grad_norm": 6.447486400604248,
      "learning_rate": 1.87735297556413e-05,
      "loss": 0.638,
      "step": 1050
    },
    {
      "epoch": 0.1929147667485093,
      "grad_norm": 37.22871780395508,
      "learning_rate": 1.8715070735414477e-05,
      "loss": 0.5876,
      "step": 1100
    },
    {
      "epoch": 0.20168361978253244,
      "grad_norm": 42.21690368652344,
      "learning_rate": 1.8656611715187655e-05,
      "loss": 0.5677,
      "step": 1150
    },
    {
      "epoch": 0.2104524728165556,
      "grad_norm": 11.182705879211426,
      "learning_rate": 1.8598152694960832e-05,
      "loss": 0.5613,
      "step": 1200
    },
    {
      "epoch": 0.21922132585057874,
      "grad_norm": 26.606956481933594,
      "learning_rate": 1.8539693674734014e-05,
      "loss": 0.5852,
      "step": 1250
    },
    {
      "epoch": 0.2279901788846019,
      "grad_norm": 23.74173355102539,
      "learning_rate": 1.848123465450719e-05,
      "loss": 0.6553,
      "step": 1300
    },
    {
      "epoch": 0.23675903191862505,
      "grad_norm": 14.445143699645996,
      "learning_rate": 1.842277563428037e-05,
      "loss": 0.5343,
      "step": 1350
    },
    {
      "epoch": 0.24552788495264818,
      "grad_norm": 18.762821197509766,
      "learning_rate": 1.836431661405355e-05,
      "loss": 0.589,
      "step": 1400
    },
    {
      "epoch": 0.25429673798667135,
      "grad_norm": 12.612329483032227,
      "learning_rate": 1.8305857593826728e-05,
      "loss": 0.5086,
      "step": 1450
    },
    {
      "epoch": 0.2630655910206945,
      "grad_norm": 14.593262672424316,
      "learning_rate": 1.824739857359991e-05,
      "loss": 0.6132,
      "step": 1500
    },
    {
      "epoch": 0.2718344440547176,
      "grad_norm": 22.87300682067871,
      "learning_rate": 1.8188939553373087e-05,
      "loss": 0.464,
      "step": 1550
    },
    {
      "epoch": 0.28060329708874077,
      "grad_norm": 27.788814544677734,
      "learning_rate": 1.8130480533146265e-05,
      "loss": 0.6391,
      "step": 1600
    },
    {
      "epoch": 0.28937215012276396,
      "grad_norm": 12.783684730529785,
      "learning_rate": 1.8072021512919446e-05,
      "loss": 0.5467,
      "step": 1650
    },
    {
      "epoch": 0.2981410031567871,
      "grad_norm": 20.185020446777344,
      "learning_rate": 1.8013562492692624e-05,
      "loss": 0.517,
      "step": 1700
    },
    {
      "epoch": 0.30690985619081024,
      "grad_norm": 13.459314346313477,
      "learning_rate": 1.79551034724658e-05,
      "loss": 0.6349,
      "step": 1750
    },
    {
      "epoch": 0.3156787092248334,
      "grad_norm": 9.261687278747559,
      "learning_rate": 1.7896644452238982e-05,
      "loss": 0.5552,
      "step": 1800
    },
    {
      "epoch": 0.3244475622588565,
      "grad_norm": 8.153563499450684,
      "learning_rate": 1.783818543201216e-05,
      "loss": 0.5144,
      "step": 1850
    },
    {
      "epoch": 0.3332164152928797,
      "grad_norm": 29.9373722076416,
      "learning_rate": 1.777972641178534e-05,
      "loss": 0.5064,
      "step": 1900
    },
    {
      "epoch": 0.34198526832690285,
      "grad_norm": 10.64893627166748,
      "learning_rate": 1.772126739155852e-05,
      "loss": 0.5561,
      "step": 1950
    },
    {
      "epoch": 0.350754121360926,
      "grad_norm": 39.572147369384766,
      "learning_rate": 1.76628083713317e-05,
      "loss": 0.5833,
      "step": 2000
    },
    {
      "epoch": 0.3595229743949491,
      "grad_norm": 34.190162658691406,
      "learning_rate": 1.7604349351104878e-05,
      "loss": 0.5438,
      "step": 2050
    },
    {
      "epoch": 0.3682918274289723,
      "grad_norm": 8.484058380126953,
      "learning_rate": 1.7545890330878056e-05,
      "loss": 0.5719,
      "step": 2100
    },
    {
      "epoch": 0.37706068046299546,
      "grad_norm": 24.56251335144043,
      "learning_rate": 1.7487431310651234e-05,
      "loss": 0.506,
      "step": 2150
    },
    {
      "epoch": 0.3858295334970186,
      "grad_norm": 22.614343643188477,
      "learning_rate": 1.742897229042441e-05,
      "loss": 0.4917,
      "step": 2200
    },
    {
      "epoch": 0.39459838653104173,
      "grad_norm": 25.911060333251953,
      "learning_rate": 1.7370513270197592e-05,
      "loss": 0.5379,
      "step": 2250
    },
    {
      "epoch": 0.4033672395650649,
      "grad_norm": 23.40053939819336,
      "learning_rate": 1.731205424997077e-05,
      "loss": 0.5787,
      "step": 2300
    },
    {
      "epoch": 0.41213609259908807,
      "grad_norm": 23.049266815185547,
      "learning_rate": 1.725359522974395e-05,
      "loss": 0.6302,
      "step": 2350
    },
    {
      "epoch": 0.4209049456331112,
      "grad_norm": 27.825387954711914,
      "learning_rate": 1.719513620951713e-05,
      "loss": 0.5667,
      "step": 2400
    },
    {
      "epoch": 0.42967379866713434,
      "grad_norm": 5.987380027770996,
      "learning_rate": 1.713667718929031e-05,
      "loss": 0.4961,
      "step": 2450
    },
    {
      "epoch": 0.4384426517011575,
      "grad_norm": 27.40089225769043,
      "learning_rate": 1.7078218169063488e-05,
      "loss": 0.6228,
      "step": 2500
    },
    {
      "epoch": 0.4472115047351806,
      "grad_norm": 20.172792434692383,
      "learning_rate": 1.701975914883667e-05,
      "loss": 0.5113,
      "step": 2550
    },
    {
      "epoch": 0.4559803577692038,
      "grad_norm": 12.78254222869873,
      "learning_rate": 1.6961300128609847e-05,
      "loss": 0.5665,
      "step": 2600
    },
    {
      "epoch": 0.46474921080322695,
      "grad_norm": 21.279376983642578,
      "learning_rate": 1.6902841108383025e-05,
      "loss": 0.5743,
      "step": 2650
    },
    {
      "epoch": 0.4735180638372501,
      "grad_norm": 7.306910991668701,
      "learning_rate": 1.6844382088156202e-05,
      "loss": 0.5124,
      "step": 2700
    },
    {
      "epoch": 0.48228691687127323,
      "grad_norm": 17.388811111450195,
      "learning_rate": 1.6785923067929384e-05,
      "loss": 0.6083,
      "step": 2750
    },
    {
      "epoch": 0.49105576990529637,
      "grad_norm": 11.664456367492676,
      "learning_rate": 1.672746404770256e-05,
      "loss": 0.577,
      "step": 2800
    },
    {
      "epoch": 0.49982462293931956,
      "grad_norm": 32.488555908203125,
      "learning_rate": 1.666900502747574e-05,
      "loss": 0.4952,
      "step": 2850
    },
    {
      "epoch": 0.5085934759733427,
      "grad_norm": 18.25028419494629,
      "learning_rate": 1.661054600724892e-05,
      "loss": 0.5554,
      "step": 2900
    },
    {
      "epoch": 0.5173623290073658,
      "grad_norm": 5.875308990478516,
      "learning_rate": 1.6552086987022098e-05,
      "loss": 0.5322,
      "step": 2950
    },
    {
      "epoch": 0.526131182041389,
      "grad_norm": 7.058801651000977,
      "learning_rate": 1.649362796679528e-05,
      "loss": 0.5685,
      "step": 3000
    },
    {
      "epoch": 0.5349000350754122,
      "grad_norm": 14.5927095413208,
      "learning_rate": 1.6435168946568457e-05,
      "loss": 0.5539,
      "step": 3050
    },
    {
      "epoch": 0.5436688881094353,
      "grad_norm": 17.978851318359375,
      "learning_rate": 1.6376709926341635e-05,
      "loss": 0.5812,
      "step": 3100
    },
    {
      "epoch": 0.5524377411434584,
      "grad_norm": 23.95724105834961,
      "learning_rate": 1.6318250906114816e-05,
      "loss": 0.4787,
      "step": 3150
    },
    {
      "epoch": 0.5612065941774815,
      "grad_norm": 13.50792407989502,
      "learning_rate": 1.6259791885887994e-05,
      "loss": 0.5762,
      "step": 3200
    },
    {
      "epoch": 0.5699754472115047,
      "grad_norm": 23.8729190826416,
      "learning_rate": 1.620133286566117e-05,
      "loss": 0.5064,
      "step": 3250
    },
    {
      "epoch": 0.5787443002455279,
      "grad_norm": 9.210742950439453,
      "learning_rate": 1.6142873845434353e-05,
      "loss": 0.5452,
      "step": 3300
    },
    {
      "epoch": 0.587513153279551,
      "grad_norm": 11.12401294708252,
      "learning_rate": 1.608441482520753e-05,
      "loss": 0.567,
      "step": 3350
    },
    {
      "epoch": 0.5962820063135742,
      "grad_norm": 28.57172203063965,
      "learning_rate": 1.602595580498071e-05,
      "loss": 0.5299,
      "step": 3400
    },
    {
      "epoch": 0.6050508593475973,
      "grad_norm": 20.411325454711914,
      "learning_rate": 1.596749678475389e-05,
      "loss": 0.5178,
      "step": 3450
    },
    {
      "epoch": 0.6138197123816205,
      "grad_norm": 19.424659729003906,
      "learning_rate": 1.590903776452707e-05,
      "loss": 0.5941,
      "step": 3500
    },
    {
      "epoch": 0.6225885654156437,
      "grad_norm": 15.695929527282715,
      "learning_rate": 1.5850578744300248e-05,
      "loss": 0.5515,
      "step": 3550
    },
    {
      "epoch": 0.6313574184496668,
      "grad_norm": 21.811094284057617,
      "learning_rate": 1.5792119724073426e-05,
      "loss": 0.5619,
      "step": 3600
    },
    {
      "epoch": 0.64012627148369,
      "grad_norm": 45.32130813598633,
      "learning_rate": 1.5733660703846604e-05,
      "loss": 0.5335,
      "step": 3650
    },
    {
      "epoch": 0.648895124517713,
      "grad_norm": 22.707542419433594,
      "learning_rate": 1.567520168361978e-05,
      "loss": 0.5493,
      "step": 3700
    },
    {
      "epoch": 0.6576639775517362,
      "grad_norm": 33.2109375,
      "learning_rate": 1.5616742663392962e-05,
      "loss": 0.5691,
      "step": 3750
    },
    {
      "epoch": 0.6664328305857594,
      "grad_norm": 16.81756591796875,
      "learning_rate": 1.555828364316614e-05,
      "loss": 0.5369,
      "step": 3800
    },
    {
      "epoch": 0.6752016836197825,
      "grad_norm": 22.336523056030273,
      "learning_rate": 1.549982462293932e-05,
      "loss": 0.4674,
      "step": 3850
    },
    {
      "epoch": 0.6839705366538057,
      "grad_norm": 11.336613655090332,
      "learning_rate": 1.54413656027125e-05,
      "loss": 0.6177,
      "step": 3900
    },
    {
      "epoch": 0.6927393896878288,
      "grad_norm": 12.028944969177246,
      "learning_rate": 1.538290658248568e-05,
      "loss": 0.5452,
      "step": 3950
    },
    {
      "epoch": 0.701508242721852,
      "grad_norm": 16.315956115722656,
      "learning_rate": 1.5324447562258858e-05,
      "loss": 0.6158,
      "step": 4000
    },
    {
      "epoch": 0.7102770957558752,
      "grad_norm": 14.806061744689941,
      "learning_rate": 1.5265988542032036e-05,
      "loss": 0.4939,
      "step": 4050
    },
    {
      "epoch": 0.7190459487898982,
      "grad_norm": 21.238037109375,
      "learning_rate": 1.5207529521805215e-05,
      "loss": 0.5083,
      "step": 4100
    },
    {
      "epoch": 0.7278148018239214,
      "grad_norm": 19.869348526000977,
      "learning_rate": 1.5149070501578396e-05,
      "loss": 0.576,
      "step": 4150
    },
    {
      "epoch": 0.7365836548579446,
      "grad_norm": 27.60514259338379,
      "learning_rate": 1.5090611481351574e-05,
      "loss": 0.5515,
      "step": 4200
    },
    {
      "epoch": 0.7453525078919677,
      "grad_norm": 3.3069827556610107,
      "learning_rate": 1.5032152461124754e-05,
      "loss": 0.5304,
      "step": 4250
    },
    {
      "epoch": 0.7541213609259909,
      "grad_norm": 14.032247543334961,
      "learning_rate": 1.4973693440897931e-05,
      "loss": 0.5435,
      "step": 4300
    },
    {
      "epoch": 0.762890213960014,
      "grad_norm": 4.6077046394348145,
      "learning_rate": 1.4915234420671109e-05,
      "loss": 0.6205,
      "step": 4350
    },
    {
      "epoch": 0.7716590669940372,
      "grad_norm": 22.202877044677734,
      "learning_rate": 1.485677540044429e-05,
      "loss": 0.5564,
      "step": 4400
    },
    {
      "epoch": 0.7804279200280604,
      "grad_norm": 20.091707229614258,
      "learning_rate": 1.4798316380217468e-05,
      "loss": 0.5128,
      "step": 4450
    },
    {
      "epoch": 0.7891967730620835,
      "grad_norm": 16.959680557250977,
      "learning_rate": 1.4739857359990648e-05,
      "loss": 0.5554,
      "step": 4500
    },
    {
      "epoch": 0.7979656260961067,
      "grad_norm": 32.54659652709961,
      "learning_rate": 1.4681398339763825e-05,
      "loss": 0.5405,
      "step": 4550
    },
    {
      "epoch": 0.8067344791301297,
      "grad_norm": 20.55562973022461,
      "learning_rate": 1.4622939319537006e-05,
      "loss": 0.5631,
      "step": 4600
    },
    {
      "epoch": 0.8155033321641529,
      "grad_norm": 12.761007308959961,
      "learning_rate": 1.4564480299310184e-05,
      "loss": 0.5248,
      "step": 4650
    },
    {
      "epoch": 0.8242721851981761,
      "grad_norm": 19.39558982849121,
      "learning_rate": 1.4506021279083364e-05,
      "loss": 0.5092,
      "step": 4700
    },
    {
      "epoch": 0.8330410382321992,
      "grad_norm": 12.880406379699707,
      "learning_rate": 1.4447562258856543e-05,
      "loss": 0.5431,
      "step": 4750
    },
    {
      "epoch": 0.8418098912662224,
      "grad_norm": 49.78459548950195,
      "learning_rate": 1.4389103238629723e-05,
      "loss": 0.5618,
      "step": 4800
    },
    {
      "epoch": 0.8505787443002455,
      "grad_norm": 29.866716384887695,
      "learning_rate": 1.43306442184029e-05,
      "loss": 0.4675,
      "step": 4850
    },
    {
      "epoch": 0.8593475973342687,
      "grad_norm": 13.00359058380127,
      "learning_rate": 1.4272185198176081e-05,
      "loss": 0.5232,
      "step": 4900
    },
    {
      "epoch": 0.8681164503682919,
      "grad_norm": 9.941661834716797,
      "learning_rate": 1.421372617794926e-05,
      "loss": 0.5796,
      "step": 4950
    },
    {
      "epoch": 0.876885303402315,
      "grad_norm": 33.11953353881836,
      "learning_rate": 1.4155267157722439e-05,
      "loss": 0.5015,
      "step": 5000
    },
    {
      "epoch": 0.8856541564363382,
      "grad_norm": 9.219670295715332,
      "learning_rate": 1.4096808137495616e-05,
      "loss": 0.5629,
      "step": 5050
    },
    {
      "epoch": 0.8944230094703612,
      "grad_norm": 20.85619354248047,
      "learning_rate": 1.4038349117268794e-05,
      "loss": 0.6097,
      "step": 5100
    },
    {
      "epoch": 0.9031918625043844,
      "grad_norm": 25.27180290222168,
      "learning_rate": 1.3979890097041975e-05,
      "loss": 0.5635,
      "step": 5150
    },
    {
      "epoch": 0.9119607155384076,
      "grad_norm": 11.161294937133789,
      "learning_rate": 1.3921431076815153e-05,
      "loss": 0.555,
      "step": 5200
    },
    {
      "epoch": 0.9207295685724307,
      "grad_norm": 21.620391845703125,
      "learning_rate": 1.3862972056588333e-05,
      "loss": 0.4768,
      "step": 5250
    },
    {
      "epoch": 0.9294984216064539,
      "grad_norm": 32.37575149536133,
      "learning_rate": 1.380451303636151e-05,
      "loss": 0.535,
      "step": 5300
    },
    {
      "epoch": 0.938267274640477,
      "grad_norm": 19.793848037719727,
      "learning_rate": 1.3746054016134691e-05,
      "loss": 0.515,
      "step": 5350
    },
    {
      "epoch": 0.9470361276745002,
      "grad_norm": 14.29688549041748,
      "learning_rate": 1.368759499590787e-05,
      "loss": 0.5106,
      "step": 5400
    },
    {
      "epoch": 0.9558049807085234,
      "grad_norm": 7.229643821716309,
      "learning_rate": 1.3629135975681049e-05,
      "loss": 0.4879,
      "step": 5450
    },
    {
      "epoch": 0.9645738337425465,
      "grad_norm": 19.01701545715332,
      "learning_rate": 1.3570676955454228e-05,
      "loss": 0.5309,
      "step": 5500
    },
    {
      "epoch": 0.9733426867765697,
      "grad_norm": 14.163739204406738,
      "learning_rate": 1.3512217935227408e-05,
      "loss": 0.5479,
      "step": 5550
    },
    {
      "epoch": 0.9821115398105927,
      "grad_norm": 23.07871437072754,
      "learning_rate": 1.3453758915000585e-05,
      "loss": 0.5499,
      "step": 5600
    },
    {
      "epoch": 0.9908803928446159,
      "grad_norm": 15.059358596801758,
      "learning_rate": 1.3395299894773765e-05,
      "loss": 0.5111,
      "step": 5650
    },
    {
      "epoch": 0.9996492458786391,
      "grad_norm": 12.024609565734863,
      "learning_rate": 1.3336840874546944e-05,
      "loss": 0.5256,
      "step": 5700
    },
    {
      "epoch": 1.0,
      "eval_accuracy": 0.789,
      "eval_f1_macro": 0.7805747389723933,
      "eval_loss": 0.5145531296730042,
      "eval_runtime": 70.2761,
      "eval_samples_per_second": 28.459,
      "eval_steps_per_second": 3.557,
      "step": 5702
    },
    {
      "epoch": 1.0084180989126623,
      "grad_norm": 20.255237579345703,
      "learning_rate": 1.3278381854320124e-05,
      "loss": 0.4043,
      "step": 5750
    },
    {
      "epoch": 1.0171869519466854,
      "grad_norm": 15.370113372802734,
      "learning_rate": 1.3219922834093301e-05,
      "loss": 0.3129,
      "step": 5800
    },
    {
      "epoch": 1.0259558049807085,
      "grad_norm": 14.73673152923584,
      "learning_rate": 1.316146381386648e-05,
      "loss": 0.4248,
      "step": 5850
    },
    {
      "epoch": 1.0347246580147316,
      "grad_norm": 45.69490432739258,
      "learning_rate": 1.310300479363966e-05,
      "loss": 0.3997,
      "step": 5900
    },
    {
      "epoch": 1.0434935110487549,
      "grad_norm": 14.636340141296387,
      "learning_rate": 1.3044545773412838e-05,
      "loss": 0.3847,
      "step": 5950
    },
    {
      "epoch": 1.052262364082778,
      "grad_norm": 22.41285514831543,
      "learning_rate": 1.2986086753186018e-05,
      "loss": 0.3627,
      "step": 6000
    },
    {
      "epoch": 1.061031217116801,
      "grad_norm": 9.803618431091309,
      "learning_rate": 1.2927627732959195e-05,
      "loss": 0.3957,
      "step": 6050
    },
    {
      "epoch": 1.0698000701508243,
      "grad_norm": 13.412959098815918,
      "learning_rate": 1.2869168712732376e-05,
      "loss": 0.4151,
      "step": 6100
    },
    {
      "epoch": 1.0785689231848474,
      "grad_norm": 29.55169677734375,
      "learning_rate": 1.2810709692505554e-05,
      "loss": 0.4198,
      "step": 6150
    },
    {
      "epoch": 1.0873377762188705,
      "grad_norm": 18.142505645751953,
      "learning_rate": 1.2752250672278734e-05,
      "loss": 0.4595,
      "step": 6200
    },
    {
      "epoch": 1.0961066292528938,
      "grad_norm": 43.940616607666016,
      "learning_rate": 1.2693791652051911e-05,
      "loss": 0.279,
      "step": 6250
    },
    {
      "epoch": 1.104875482286917,
      "grad_norm": 38.03789138793945,
      "learning_rate": 1.2635332631825093e-05,
      "loss": 0.374,
      "step": 6300
    },
    {
      "epoch": 1.11364433532094,
      "grad_norm": 39.98751449584961,
      "learning_rate": 1.257687361159827e-05,
      "loss": 0.3696,
      "step": 6350
    },
    {
      "epoch": 1.122413188354963,
      "grad_norm": 37.49401092529297,
      "learning_rate": 1.251841459137145e-05,
      "loss": 0.4184,
      "step": 6400
    },
    {
      "epoch": 1.1311820413889864,
      "grad_norm": 29.957324981689453,
      "learning_rate": 1.245995557114463e-05,
      "loss": 0.4339,
      "step": 6450
    },
    {
      "epoch": 1.1399508944230095,
      "grad_norm": 30.44612693786621,
      "learning_rate": 1.2401496550917809e-05,
      "loss": 0.3347,
      "step": 6500
    },
    {
      "epoch": 1.1487197474570325,
      "grad_norm": 18.99996566772461,
      "learning_rate": 1.2343037530690986e-05,
      "loss": 0.3537,
      "step": 6550
    },
    {
      "epoch": 1.1574886004910558,
      "grad_norm": 12.023489952087402,
      "learning_rate": 1.2284578510464164e-05,
      "loss": 0.3909,
      "step": 6600
    },
    {
      "epoch": 1.166257453525079,
      "grad_norm": 21.85649299621582,
      "learning_rate": 1.2226119490237345e-05,
      "loss": 0.4583,
      "step": 6650
    },
    {
      "epoch": 1.175026306559102,
      "grad_norm": 27.899316787719727,
      "learning_rate": 1.2167660470010523e-05,
      "loss": 0.4004,
      "step": 6700
    },
    {
      "epoch": 1.1837951595931253,
      "grad_norm": 23.307971954345703,
      "learning_rate": 1.2109201449783703e-05,
      "loss": 0.4361,
      "step": 6750
    },
    {
      "epoch": 1.1925640126271484,
      "grad_norm": 25.434471130371094,
      "learning_rate": 1.205074242955688e-05,
      "loss": 0.4259,
      "step": 6800
    },
    {
      "epoch": 1.2013328656611715,
      "grad_norm": 16.505924224853516,
      "learning_rate": 1.1992283409330061e-05,
      "loss": 0.3684,
      "step": 6850
    },
    {
      "epoch": 1.2101017186951948,
      "grad_norm": 26.962135314941406,
      "learning_rate": 1.193382438910324e-05,
      "loss": 0.4465,
      "step": 6900
    },
    {
      "epoch": 1.2188705717292179,
      "grad_norm": 29.44926643371582,
      "learning_rate": 1.1875365368876419e-05,
      "loss": 0.4603,
      "step": 6950
    },
    {
      "epoch": 1.227639424763241,
      "grad_norm": 13.033198356628418,
      "learning_rate": 1.1816906348649596e-05,
      "loss": 0.4166,
      "step": 7000
    },
    {
      "epoch": 1.236408277797264,
      "grad_norm": 19.927719116210938,
      "learning_rate": 1.1758447328422778e-05,
      "loss": 0.3574,
      "step": 7050
    },
    {
      "epoch": 1.2451771308312873,
      "grad_norm": 19.624805450439453,
      "learning_rate": 1.1699988308195955e-05,
      "loss": 0.4765,
      "step": 7100
    },
    {
      "epoch": 1.2539459838653104,
      "grad_norm": 7.176894664764404,
      "learning_rate": 1.1641529287969135e-05,
      "loss": 0.4192,
      "step": 7150
    },
    {
      "epoch": 1.2627148368993335,
      "grad_norm": 36.939483642578125,
      "learning_rate": 1.1583070267742314e-05,
      "loss": 0.3625,
      "step": 7200
    },
    {
      "epoch": 1.2714836899333566,
      "grad_norm": 72.67568969726562,
      "learning_rate": 1.1524611247515494e-05,
      "loss": 0.4144,
      "step": 7250
    },
    {
      "epoch": 1.28025254296738,
      "grad_norm": 31.93866539001465,
      "learning_rate": 1.1466152227288671e-05,
      "loss": 0.3274,
      "step": 7300
    },
    {
      "epoch": 1.289021396001403,
      "grad_norm": 49.4859619140625,
      "learning_rate": 1.140769320706185e-05,
      "loss": 0.3897,
      "step": 7350
    },
    {
      "epoch": 1.297790249035426,
      "grad_norm": 12.392868995666504,
      "learning_rate": 1.134923418683503e-05,
      "loss": 0.4814,
      "step": 7400
    },
    {
      "epoch": 1.3065591020694494,
      "grad_norm": 32.684261322021484,
      "learning_rate": 1.1290775166608208e-05,
      "loss": 0.3126,
      "step": 7450
    },
    {
      "epoch": 1.3153279551034724,
      "grad_norm": 31.56937026977539,
      "learning_rate": 1.1232316146381388e-05,
      "loss": 0.3262,
      "step": 7500
    },
    {
      "epoch": 1.3240968081374955,
      "grad_norm": 35.18944549560547,
      "learning_rate": 1.1173857126154565e-05,
      "loss": 0.3666,
      "step": 7550
    },
    {
      "epoch": 1.3328656611715188,
      "grad_norm": 12.742534637451172,
      "learning_rate": 1.1115398105927746e-05,
      "loss": 0.3912,
      "step": 7600
    },
    {
      "epoch": 1.341634514205542,
      "grad_norm": 19.96637535095215,
      "learning_rate": 1.1056939085700924e-05,
      "loss": 0.4099,
      "step": 7650
    },
    {
      "epoch": 1.350403367239565,
      "grad_norm": 25.026046752929688,
      "learning_rate": 1.0998480065474104e-05,
      "loss": 0.3537,
      "step": 7700
    },
    {
      "epoch": 1.3591722202735883,
      "grad_norm": 22.703763961791992,
      "learning_rate": 1.0940021045247281e-05,
      "loss": 0.3886,
      "step": 7750
    },
    {
      "epoch": 1.3679410733076114,
      "grad_norm": 7.014620304107666,
      "learning_rate": 1.0881562025020463e-05,
      "loss": 0.3337,
      "step": 7800
    },
    {
      "epoch": 1.3767099263416345,
      "grad_norm": 44.47578048706055,
      "learning_rate": 1.082310300479364e-05,
      "loss": 0.4142,
      "step": 7850
    },
    {
      "epoch": 1.3854787793756578,
      "grad_norm": 13.195672988891602,
      "learning_rate": 1.076464398456682e-05,
      "loss": 0.4088,
      "step": 7900
    },
    {
      "epoch": 1.3942476324096809,
      "grad_norm": 9.095497131347656,
      "learning_rate": 1.070618496434e-05,
      "loss": 0.3293,
      "step": 7950
    },
    {
      "epoch": 1.403016485443704,
      "grad_norm": 22.51821517944336,
      "learning_rate": 1.0647725944113179e-05,
      "loss": 0.438,
      "step": 8000
    },
    {
      "epoch": 1.4117853384777272,
      "grad_norm": 45.33659744262695,
      "learning_rate": 1.0589266923886356e-05,
      "loss": 0.3719,
      "step": 8050
    },
    {
      "epoch": 1.4205541915117503,
      "grad_norm": 21.35817527770996,
      "learning_rate": 1.0530807903659534e-05,
      "loss": 0.3434,
      "step": 8100
    },
    {
      "epoch": 1.4293230445457734,
      "grad_norm": 20.396854400634766,
      "learning_rate": 1.0472348883432715e-05,
      "loss": 0.3457,
      "step": 8150
    },
    {
      "epoch": 1.4380918975797965,
      "grad_norm": 13.921099662780762,
      "learning_rate": 1.0413889863205893e-05,
      "loss": 0.4057,
      "step": 8200
    },
    {
      "epoch": 1.4468607506138196,
      "grad_norm": 6.180751800537109,
      "learning_rate": 1.0355430842979073e-05,
      "loss": 0.4062,
      "step": 8250
    },
    {
      "epoch": 1.4556296036478429,
      "grad_norm": 21.473548889160156,
      "learning_rate": 1.029697182275225e-05,
      "loss": 0.3553,
      "step": 8300
    },
    {
      "epoch": 1.464398456681866,
      "grad_norm": 16.006061553955078,
      "learning_rate": 1.0238512802525431e-05,
      "loss": 0.4115,
      "step": 8350
    },
    {
      "epoch": 1.473167309715889,
      "grad_norm": 44.7129020690918,
      "learning_rate": 1.018005378229861e-05,
      "loss": 0.3817,
      "step": 8400
    },
    {
      "epoch": 1.4819361627499124,
      "grad_norm": 32.415122985839844,
      "learning_rate": 1.0121594762071789e-05,
      "loss": 0.3446,
      "step": 8450
    },
    {
      "epoch": 1.4907050157839354,
      "grad_norm": 49.77564239501953,
      "learning_rate": 1.0063135741844966e-05,
      "loss": 0.4962,
      "step": 8500
    },
    {
      "epoch": 1.4994738688179585,
      "grad_norm": 25.050458908081055,
      "learning_rate": 1.0004676721618148e-05,
      "loss": 0.3802,
      "step": 8550
    },
    {
      "epoch": 1.5082427218519818,
      "grad_norm": 32.63443374633789,
      "learning_rate": 9.946217701391325e-06,
      "loss": 0.3152,
      "step": 8600
    },
    {
      "epoch": 1.517011574886005,
      "grad_norm": 43.09700393676758,
      "learning_rate": 9.887758681164505e-06,
      "loss": 0.356,
      "step": 8650
    },
    {
      "epoch": 1.525780427920028,
      "grad_norm": 12.838777542114258,
      "learning_rate": 9.829299660937684e-06,
      "loss": 0.3689,
      "step": 8700
    },
    {
      "epoch": 1.5345492809540513,
      "grad_norm": 37.303958892822266,
      "learning_rate": 9.770840640710862e-06,
      "loss": 0.3943,
      "step": 8750
    },
    {
      "epoch": 1.5433181339880744,
      "grad_norm": 39.61430740356445,
      "learning_rate": 9.712381620484041e-06,
      "loss": 0.3986,
      "step": 8800
    },
    {
      "epoch": 1.5520869870220975,
      "grad_norm": 19.16562271118164,
      "learning_rate": 9.653922600257221e-06,
      "loss": 0.387,
      "step": 8850
    },
    {
      "epoch": 1.5608558400561208,
      "grad_norm": 2.130791425704956,
      "learning_rate": 9.5954635800304e-06,
      "loss": 0.2484,
      "step": 8900
    },
    {
      "epoch": 1.5696246930901439,
      "grad_norm": 23.431337356567383,
      "learning_rate": 9.537004559803578e-06,
      "loss": 0.4199,
      "step": 8950
    },
    {
      "epoch": 1.578393546124167,
      "grad_norm": 0.8971916437149048,
      "learning_rate": 9.478545539576758e-06,
      "loss": 0.3437,
      "step": 9000
    },
    {
      "epoch": 1.5871623991581902,
      "grad_norm": 1.74393630027771,
      "learning_rate": 9.420086519349937e-06,
      "loss": 0.439,
      "step": 9050
    },
    {
      "epoch": 1.595931252192213,
      "grad_norm": 21.02110481262207,
      "learning_rate": 9.361627499123116e-06,
      "loss": 0.3943,
      "step": 9100
    },
    {
      "epoch": 1.6047001052262364,
      "grad_norm": 17.51079750061035,
      "learning_rate": 9.303168478896294e-06,
      "loss": 0.431,
      "step": 9150
    },
    {
      "epoch": 1.6134689582602597,
      "grad_norm": 32.25886917114258,
      "learning_rate": 9.244709458669474e-06,
      "loss": 0.4385,
      "step": 9200
    },
    {
      "epoch": 1.6222378112942826,
      "grad_norm": 9.848480224609375,
      "learning_rate": 9.186250438442651e-06,
      "loss": 0.4155,
      "step": 9250
    },
    {
      "epoch": 1.6310066643283059,
      "grad_norm": 32.25238037109375,
      "learning_rate": 9.127791418215831e-06,
      "loss": 0.3772,
      "step": 9300
    },
    {
      "epoch": 1.639775517362329,
      "grad_norm": 47.48023223876953,
      "learning_rate": 9.06933239798901e-06,
      "loss": 0.3711,
      "step": 9350
    },
    {
      "epoch": 1.648544370396352,
      "grad_norm": 3.549586296081543,
      "learning_rate": 9.01087337776219e-06,
      "loss": 0.3763,
      "step": 9400
    },
    {
      "epoch": 1.6573132234303753,
      "grad_norm": 32.22633361816406,
      "learning_rate": 8.952414357535368e-06,
      "loss": 0.3415,
      "step": 9450
    },
    {
      "epoch": 1.6660820764643984,
      "grad_norm": 36.31272506713867,
      "learning_rate": 8.893955337308547e-06,
      "loss": 0.3512,
      "step": 9500
    },
    {
      "epoch": 1.6748509294984215,
      "grad_norm": 11.606925010681152,
      "learning_rate": 8.835496317081726e-06,
      "loss": 0.3279,
      "step": 9550
    },
    {
      "epoch": 1.6836197825324448,
      "grad_norm": 19.843717575073242,
      "learning_rate": 8.777037296854906e-06,
      "loss": 0.3628,
      "step": 9600
    },
    {
      "epoch": 1.692388635566468,
      "grad_norm": 12.774320602416992,
      "learning_rate": 8.718578276628085e-06,
      "loss": 0.4225,
      "step": 9650
    },
    {
      "epoch": 1.701157488600491,
      "grad_norm": 26.07146453857422,
      "learning_rate": 8.660119256401263e-06,
      "loss": 0.3472,
      "step": 9700
    },
    {
      "epoch": 1.7099263416345143,
      "grad_norm": 20.569786071777344,
      "learning_rate": 8.601660236174443e-06,
      "loss": 0.4138,
      "step": 9750
    },
    {
      "epoch": 1.7186951946685374,
      "grad_norm": 14.577851295471191,
      "learning_rate": 8.543201215947622e-06,
      "loss": 0.3438,
      "step": 9800
    },
    {
      "epoch": 1.7274640477025605,
      "grad_norm": 31.178712844848633,
      "learning_rate": 8.484742195720801e-06,
      "loss": 0.3942,
      "step": 9850
    },
    {
      "epoch": 1.7362329007365838,
      "grad_norm": 9.922934532165527,
      "learning_rate": 8.42628317549398e-06,
      "loss": 0.3462,
      "step": 9900
    },
    {
      "epoch": 1.7450017537706068,
      "grad_norm": 21.470083236694336,
      "learning_rate": 8.367824155267159e-06,
      "loss": 0.3966,
      "step": 9950
    },
    {
      "epoch": 1.75377060680463,
      "grad_norm": 45.05971145629883,
      "learning_rate": 8.309365135040336e-06,
      "loss": 0.3766,
      "step": 10000
    },
    {
      "epoch": 1.7625394598386532,
      "grad_norm": 42.73244094848633,
      "learning_rate": 8.250906114813516e-06,
      "loss": 0.3034,
      "step": 10050
    },
    {
      "epoch": 1.771308312872676,
      "grad_norm": 48.01158905029297,
      "learning_rate": 8.192447094586695e-06,
      "loss": 0.3613,
      "step": 10100
    },
    {
      "epoch": 1.7800771659066994,
      "grad_norm": 34.526344299316406,
      "learning_rate": 8.133988074359875e-06,
      "loss": 0.4676,
      "step": 10150
    },
    {
      "epoch": 1.7888460189407227,
      "grad_norm": 46.96940231323242,
      "learning_rate": 8.075529054133053e-06,
      "loss": 0.4043,
      "step": 10200
    },
    {
      "epoch": 1.7976148719747456,
      "grad_norm": 14.14054012298584,
      "learning_rate": 8.017070033906232e-06,
      "loss": 0.4201,
      "step": 10250
    },
    {
      "epoch": 1.8063837250087689,
      "grad_norm": 1.2926149368286133,
      "learning_rate": 7.958611013679411e-06,
      "loss": 0.3108,
      "step": 10300
    },
    {
      "epoch": 1.815152578042792,
      "grad_norm": 102.29524993896484,
      "learning_rate": 7.900151993452591e-06,
      "loss": 0.3713,
      "step": 10350
    },
    {
      "epoch": 1.823921431076815,
      "grad_norm": 18.125669479370117,
      "learning_rate": 7.84169297322577e-06,
      "loss": 0.4255,
      "step": 10400
    },
    {
      "epoch": 1.8326902841108383,
      "grad_norm": 12.595845222473145,
      "learning_rate": 7.783233952998948e-06,
      "loss": 0.4197,
      "step": 10450
    },
    {
      "epoch": 1.8414591371448614,
      "grad_norm": 16.70142364501953,
      "learning_rate": 7.724774932772128e-06,
      "loss": 0.3476,
      "step": 10500
    },
    {
      "epoch": 1.8502279901788845,
      "grad_norm": 3.293393611907959,
      "learning_rate": 7.666315912545307e-06,
      "loss": 0.384,
      "step": 10550
    },
    {
      "epoch": 1.8589968432129078,
      "grad_norm": 11.461469650268555,
      "learning_rate": 7.607856892318486e-06,
      "loss": 0.4018,
      "step": 10600
    },
    {
      "epoch": 1.867765696246931,
      "grad_norm": 23.27739715576172,
      "learning_rate": 7.549397872091664e-06,
      "loss": 0.408,
      "step": 10650
    },
    {
      "epoch": 1.876534549280954,
      "grad_norm": 31.58605194091797,
      "learning_rate": 7.490938851864843e-06,
      "loss": 0.3758,
      "step": 10700
    },
    {
      "epoch": 1.8853034023149773,
      "grad_norm": 41.63456726074219,
      "learning_rate": 7.432479831638022e-06,
      "loss": 0.4158,
      "step": 10750
    },
    {
      "epoch": 1.8940722553490004,
      "grad_norm": 9.942483901977539,
      "learning_rate": 7.374020811411201e-06,
      "loss": 0.3467,
      "step": 10800
    },
    {
      "epoch": 1.9028411083830234,
      "grad_norm": 11.418009757995605,
      "learning_rate": 7.31556179118438e-06,
      "loss": 0.3182,
      "step": 10850
    },
    {
      "epoch": 1.9116099614170468,
      "grad_norm": 69.1023941040039,
      "learning_rate": 7.257102770957559e-06,
      "loss": 0.3564,
      "step": 10900
    },
    {
      "epoch": 1.9203788144510698,
      "grad_norm": 18.488170623779297,
      "learning_rate": 7.198643750730738e-06,
      "loss": 0.4699,
      "step": 10950
    },
    {
      "epoch": 1.929147667485093,
      "grad_norm": 4.57938289642334,
      "learning_rate": 7.140184730503917e-06,
      "loss": 0.3675,
      "step": 11000
    },
    {
      "epoch": 1.9379165205191162,
      "grad_norm": 45.51475143432617,
      "learning_rate": 7.0817257102770964e-06,
      "loss": 0.4149,
      "step": 11050
    },
    {
      "epoch": 1.946685373553139,
      "grad_norm": 23.379974365234375,
      "learning_rate": 7.023266690050276e-06,
      "loss": 0.3586,
      "step": 11100
    },
    {
      "epoch": 1.9554542265871624,
      "grad_norm": 64.069580078125,
      "learning_rate": 6.9648076698234545e-06,
      "loss": 0.3946,
      "step": 11150
    },
    {
      "epoch": 1.9642230796211857,
      "grad_norm": 41.48124694824219,
      "learning_rate": 6.906348649596634e-06,
      "loss": 0.4424,
      "step": 11200
    },
    {
      "epoch": 1.9729919326552086,
      "grad_norm": 27.82333755493164,
      "learning_rate": 6.8478896293698125e-06,
      "loss": 0.3784,
      "step": 11250
    },
    {
      "epoch": 1.9817607856892319,
      "grad_norm": 13.707903861999512,
      "learning_rate": 6.789430609142992e-06,
      "loss": 0.3256,
      "step": 11300
    },
    {
      "epoch": 1.990529638723255,
      "grad_norm": 3.233175039291382,
      "learning_rate": 6.730971588916171e-06,
      "loss": 0.3651,
      "step": 11350
    },
    {
      "epoch": 1.999298491757278,
      "grad_norm": 37.10285949707031,
      "learning_rate": 6.672512568689349e-06,
      "loss": 0.4202,
      "step": 11400
    },
    {
      "epoch": 2.0,
      "eval_accuracy": 0.7905,
      "eval_f1_macro": 0.7754953823353757,
      "eval_loss": 0.6296719908714294,
      "eval_runtime": 81.4133,
      "eval_samples_per_second": 24.566,
      "eval_steps_per_second": 3.071,
      "step": 11404
    },
    {
      "epoch": 2.0080673447913013,
      "grad_norm": 63.09489059448242,
      "learning_rate": 6.614053548462528e-06,
      "loss": 0.2709,
      "step": 11450
    },
    {
      "epoch": 2.0168361978253246,
      "grad_norm": 5.78054666519165,
      "learning_rate": 6.555594528235707e-06,
      "loss": 0.2048,
      "step": 11500
    },
    {
      "epoch": 2.0256050508593475,
      "grad_norm": 26.798614501953125,
      "learning_rate": 6.497135508008886e-06,
      "loss": 0.2609,
      "step": 11550
    },
    {
      "epoch": 2.034373903893371,
      "grad_norm": 56.46695327758789,
      "learning_rate": 6.438676487782065e-06,
      "loss": 0.1769,
      "step": 11600
    },
    {
      "epoch": 2.043142756927394,
      "grad_norm": 61.258148193359375,
      "learning_rate": 6.380217467555244e-06,
      "loss": 0.2746,
      "step": 11650
    },
    {
      "epoch": 2.051911609961417,
      "grad_norm": 7.819076061248779,
      "learning_rate": 6.321758447328423e-06,
      "loss": 0.224,
      "step": 11700
    },
    {
      "epoch": 2.0606804629954403,
      "grad_norm": 0.4392627775669098,
      "learning_rate": 6.263299427101602e-06,
      "loss": 0.3198,
      "step": 11750
    },
    {
      "epoch": 2.069449316029463,
      "grad_norm": 7.151145935058594,
      "learning_rate": 6.2048404068747814e-06,
      "loss": 0.2894,
      "step": 11800
    },
    {
      "epoch": 2.0782181690634864,
      "grad_norm": 42.69435119628906,
      "learning_rate": 6.146381386647961e-06,
      "loss": 0.2744,
      "step": 11850
    },
    {
      "epoch": 2.0869870220975097,
      "grad_norm": 11.654638290405273,
      "learning_rate": 6.0879223664211395e-06,
      "loss": 0.2856,
      "step": 11900
    },
    {
      "epoch": 2.0957558751315326,
      "grad_norm": 14.3381986618042,
      "learning_rate": 6.029463346194319e-06,
      "loss": 0.3372,
      "step": 11950
    },
    {
      "epoch": 2.104524728165556,
      "grad_norm": 3.6132748126983643,
      "learning_rate": 5.9710043259674976e-06,
      "loss": 0.2736,
      "step": 12000
    },
    {
      "epoch": 2.113293581199579,
      "grad_norm": 70.74890899658203,
      "learning_rate": 5.912545305740677e-06,
      "loss": 0.1813,
      "step": 12050
    },
    {
      "epoch": 2.122062434233602,
      "grad_norm": 5.93880558013916,
      "learning_rate": 5.854086285513855e-06,
      "loss": 0.338,
      "step": 12100
    },
    {
      "epoch": 2.1308312872676254,
      "grad_norm": 3.006439447402954,
      "learning_rate": 5.795627265287033e-06,
      "loss": 0.2635,
      "step": 12150
    },
    {
      "epoch": 2.1396001403016487,
      "grad_norm": 18.225984573364258,
      "learning_rate": 5.737168245060213e-06,
      "loss": 0.3212,
      "step": 12200
    },
    {
      "epoch": 2.1483689933356716,
      "grad_norm": 25.419818878173828,
      "learning_rate": 5.678709224833392e-06,
      "loss": 0.3408,
      "step": 12250
    },
    {
      "epoch": 2.157137846369695,
      "grad_norm": 129.6936798095703,
      "learning_rate": 5.620250204606571e-06,
      "loss": 0.1789,
      "step": 12300
    },
    {
      "epoch": 2.165906699403718,
      "grad_norm": 86.34288024902344,
      "learning_rate": 5.56179118437975e-06,
      "loss": 0.275,
      "step": 12350
    },
    {
      "epoch": 2.174675552437741,
      "grad_norm": 0.16008329391479492,
      "learning_rate": 5.503332164152929e-06,
      "loss": 0.3525,
      "step": 12400
    },
    {
      "epoch": 2.1834444054717643,
      "grad_norm": 14.885706901550293,
      "learning_rate": 5.444873143926108e-06,
      "loss": 0.281,
      "step": 12450
    },
    {
      "epoch": 2.1922132585057876,
      "grad_norm": 71.17504119873047,
      "learning_rate": 5.386414123699287e-06,
      "loss": 0.2531,
      "step": 12500
    },
    {
      "epoch": 2.2009821115398105,
      "grad_norm": 2.6008312702178955,
      "learning_rate": 5.3279551034724664e-06,
      "loss": 0.3082,
      "step": 12550
    },
    {
      "epoch": 2.209750964573834,
      "grad_norm": 13.521461486816406,
      "learning_rate": 5.269496083245645e-06,
      "loss": 0.3119,
      "step": 12600
    },
    {
      "epoch": 2.2185198176078567,
      "grad_norm": 51.552860260009766,
      "learning_rate": 5.2110370630188245e-06,
      "loss": 0.3177,
      "step": 12650
    },
    {
      "epoch": 2.22728867064188,
      "grad_norm": 2.266904592514038,
      "learning_rate": 5.152578042792004e-06,
      "loss": 0.3763,
      "step": 12700
    },
    {
      "epoch": 2.2360575236759033,
      "grad_norm": 6.851681232452393,
      "learning_rate": 5.0941190225651826e-06,
      "loss": 0.295,
      "step": 12750
    },
    {
      "epoch": 2.244826376709926,
      "grad_norm": 32.07467269897461,
      "learning_rate": 5.035660002338362e-06,
      "loss": 0.1896,
      "step": 12800
    },
    {
      "epoch": 2.2535952297439494,
      "grad_norm": 1.2657779455184937,
      "learning_rate": 4.977200982111541e-06,
      "loss": 0.3172,
      "step": 12850
    },
    {
      "epoch": 2.2623640827779727,
      "grad_norm": 54.898738861083984,
      "learning_rate": 4.918741961884719e-06,
      "loss": 0.2665,
      "step": 12900
    },
    {
      "epoch": 2.2711329358119956,
      "grad_norm": 137.59890747070312,
      "learning_rate": 4.860282941657899e-06,
      "loss": 0.289,
      "step": 12950
    },
    {
      "epoch": 2.279901788846019,
      "grad_norm": 16.250158309936523,
      "learning_rate": 4.801823921431077e-06,
      "loss": 0.4064,
      "step": 13000
    },
    {
      "epoch": 2.288670641880042,
      "grad_norm": 7.246304988861084,
      "learning_rate": 4.743364901204256e-06,
      "loss": 0.2315,
      "step": 13050
    },
    {
      "epoch": 2.297439494914065,
      "grad_norm": 39.99993896484375,
      "learning_rate": 4.684905880977435e-06,
      "loss": 0.2926,
      "step": 13100
    },
    {
      "epoch": 2.3062083479480884,
      "grad_norm": 72.77037048339844,
      "learning_rate": 4.626446860750614e-06,
      "loss": 0.3402,
      "step": 13150
    },
    {
      "epoch": 2.3149772009821117,
      "grad_norm": 0.2847498059272766,
      "learning_rate": 4.567987840523793e-06,
      "loss": 0.2225,
      "step": 13200
    },
    {
      "epoch": 2.3237460540161345,
      "grad_norm": 1.5021967887878418,
      "learning_rate": 4.509528820296972e-06,
      "loss": 0.2747,
      "step": 13250
    },
    {
      "epoch": 2.332514907050158,
      "grad_norm": 0.47703397274017334,
      "learning_rate": 4.4510698000701514e-06,
      "loss": 0.2606,
      "step": 13300
    },
    {
      "epoch": 2.341283760084181,
      "grad_norm": 46.51774978637695,
      "learning_rate": 4.39261077984333e-06,
      "loss": 0.3204,
      "step": 13350
    },
    {
      "epoch": 2.350052613118204,
      "grad_norm": 4.013668060302734,
      "learning_rate": 4.334151759616509e-06,
      "loss": 0.3608,
      "step": 13400
    },
    {
      "epoch": 2.3588214661522273,
      "grad_norm": 73.83009338378906,
      "learning_rate": 4.275692739389688e-06,
      "loss": 0.3039,
      "step": 13450
    },
    {
      "epoch": 2.3675903191862506,
      "grad_norm": 32.965736389160156,
      "learning_rate": 4.217233719162867e-06,
      "loss": 0.2441,
      "step": 13500
    },
    {
      "epoch": 2.3763591722202735,
      "grad_norm": 2.1692819595336914,
      "learning_rate": 4.158774698936046e-06,
      "loss": 0.2586,
      "step": 13550
    },
    {
      "epoch": 2.385128025254297,
      "grad_norm": 97.11170959472656,
      "learning_rate": 4.100315678709226e-06,
      "loss": 0.2878,
      "step": 13600
    },
    {
      "epoch": 2.39389687828832,
      "grad_norm": 9.414681434631348,
      "learning_rate": 4.041856658482404e-06,
      "loss": 0.2407,
      "step": 13650
    },
    {
      "epoch": 2.402665731322343,
      "grad_norm": 1.9379863739013672,
      "learning_rate": 3.983397638255584e-06,
      "loss": 0.2849,
      "step": 13700
    },
    {
      "epoch": 2.4114345843563663,
      "grad_norm": 114.046630859375,
      "learning_rate": 3.924938618028762e-06,
      "loss": 0.3109,
      "step": 13750
    },
    {
      "epoch": 2.4202034373903896,
      "grad_norm": 29.153406143188477,
      "learning_rate": 3.866479597801941e-06,
      "loss": 0.2552,
      "step": 13800
    },
    {
      "epoch": 2.4289722904244124,
      "grad_norm": 0.3885180652141571,
      "learning_rate": 3.80802057757512e-06,
      "loss": 0.2708,
      "step": 13850
    },
    {
      "epoch": 2.4377411434584357,
      "grad_norm": 0.3857063055038452,
      "learning_rate": 3.749561557348299e-06,
      "loss": 0.32,
      "step": 13900
    },
    {
      "epoch": 2.4465099964924586,
      "grad_norm": 14.305619239807129,
      "learning_rate": 3.691102537121478e-06,
      "loss": 0.2764,
      "step": 13950
    },
    {
      "epoch": 2.455278849526482,
      "grad_norm": 0.3119754195213318,
      "learning_rate": 3.6326435168946574e-06,
      "loss": 0.2489,
      "step": 14000
    },
    {
      "epoch": 2.464047702560505,
      "grad_norm": 79.10985565185547,
      "learning_rate": 3.5741844966678365e-06,
      "loss": 0.3244,
      "step": 14050
    },
    {
      "epoch": 2.472816555594528,
      "grad_norm": 38.665470123291016,
      "learning_rate": 3.5157254764410155e-06,
      "loss": 0.3285,
      "step": 14100
    },
    {
      "epoch": 2.4815854086285514,
      "grad_norm": 38.77661895751953,
      "learning_rate": 3.457266456214194e-06,
      "loss": 0.3311,
      "step": 14150
    },
    {
      "epoch": 2.4903542616625747,
      "grad_norm": 0.5723811984062195,
      "learning_rate": 3.398807435987373e-06,
      "loss": 0.2407,
      "step": 14200
    },
    {
      "epoch": 2.4991231146965975,
      "grad_norm": 34.02492904663086,
      "learning_rate": 3.340348415760552e-06,
      "loss": 0.3133,
      "step": 14250
    },
    {
      "epoch": 2.507891967730621,
      "grad_norm": 104.05533599853516,
      "learning_rate": 3.281889395533731e-06,
      "loss": 0.3138,
      "step": 14300
    },
    {
      "epoch": 2.516660820764644,
      "grad_norm": 29.644329071044922,
      "learning_rate": 3.22343037530691e-06,
      "loss": 0.2421,
      "step": 14350
    },
    {
      "epoch": 2.525429673798667,
      "grad_norm": 44.31303024291992,
      "learning_rate": 3.1649713550800892e-06,
      "loss": 0.2741,
      "step": 14400
    },
    {
      "epoch": 2.5341985268326903,
      "grad_norm": 50.04707336425781,
      "learning_rate": 3.1065123348532683e-06,
      "loss": 0.2576,
      "step": 14450
    },
    {
      "epoch": 2.542967379866713,
      "grad_norm": 42.07419204711914,
      "learning_rate": 3.0480533146264473e-06,
      "loss": 0.3007,
      "step": 14500
    },
    {
      "epoch": 2.5517362329007365,
      "grad_norm": 0.06177961826324463,
      "learning_rate": 2.989594294399626e-06,
      "loss": 0.2975,
      "step": 14550
    },
    {
      "epoch": 2.56050508593476,
      "grad_norm": 7.606206893920898,
      "learning_rate": 2.931135274172805e-06,
      "loss": 0.3037,
      "step": 14600
    },
    {
      "epoch": 2.5692739389687826,
      "grad_norm": 0.23321348428726196,
      "learning_rate": 2.872676253945984e-06,
      "loss": 0.3096,
      "step": 14650
    },
    {
      "epoch": 2.578042792002806,
      "grad_norm": 59.334808349609375,
      "learning_rate": 2.814217233719163e-06,
      "loss": 0.2098,
      "step": 14700
    },
    {
      "epoch": 2.5868116450368293,
      "grad_norm": 30.766054153442383,
      "learning_rate": 2.755758213492342e-06,
      "loss": 0.2739,
      "step": 14750
    },
    {
      "epoch": 2.595580498070852,
      "grad_norm": 15.127949714660645,
      "learning_rate": 2.6972991932655215e-06,
      "loss": 0.2649,
      "step": 14800
    },
    {
      "epoch": 2.6043493511048754,
      "grad_norm": 7.303439617156982,
      "learning_rate": 2.6388401730387005e-06,
      "loss": 0.2377,
      "step": 14850
    },
    {
      "epoch": 2.6131182041388987,
      "grad_norm": 87.29512023925781,
      "learning_rate": 2.5803811528118787e-06,
      "loss": 0.2171,
      "step": 14900
    },
    {
      "epoch": 2.6218870571729216,
      "grad_norm": 10.300209045410156,
      "learning_rate": 2.521922132585058e-06,
      "loss": 0.3189,
      "step": 14950
    },
    {
      "epoch": 2.630655910206945,
      "grad_norm": 4.677660942077637,
      "learning_rate": 2.463463112358237e-06,
      "loss": 0.3325,
      "step": 15000
    },
    {
      "epoch": 2.639424763240968,
      "grad_norm": 1.7022950649261475,
      "learning_rate": 2.405004092131416e-06,
      "loss": 0.3584,
      "step": 15050
    },
    {
      "epoch": 2.648193616274991,
      "grad_norm": 0.22218240797519684,
      "learning_rate": 2.346545071904595e-06,
      "loss": 0.3559,
      "step": 15100
    },
    {
      "epoch": 2.6569624693090144,
      "grad_norm": 20.129770278930664,
      "learning_rate": 2.2880860516777742e-06,
      "loss": 0.3241,
      "step": 15150
    },
    {
      "epoch": 2.6657313223430377,
      "grad_norm": 84.94465637207031,
      "learning_rate": 2.229627031450953e-06,
      "loss": 0.3204,
      "step": 15200
    },
    {
      "epoch": 2.6745001753770605,
      "grad_norm": 73.42922973632812,
      "learning_rate": 2.171168011224132e-06,
      "loss": 0.3899,
      "step": 15250
    },
    {
      "epoch": 2.683269028411084,
      "grad_norm": 11.28256607055664,
      "learning_rate": 2.1127089909973113e-06,
      "loss": 0.252,
      "step": 15300
    },
    {
      "epoch": 2.692037881445107,
      "grad_norm": 19.243282318115234,
      "learning_rate": 2.05424997077049e-06,
      "loss": 0.2449,
      "step": 15350
    },
    {
      "epoch": 2.70080673447913,
      "grad_norm": 77.04261779785156,
      "learning_rate": 1.995790950543669e-06,
      "loss": 0.323,
      "step": 15400
    },
    {
      "epoch": 2.7095755875131533,
      "grad_norm": 131.93650817871094,
      "learning_rate": 1.937331930316848e-06,
      "loss": 0.2677,
      "step": 15450
    },
    {
      "epoch": 2.7183444405471766,
      "grad_norm": 1.497522234916687,
      "learning_rate": 1.8788729100900272e-06,
      "loss": 0.2983,
      "step": 15500
    },
    {
      "epoch": 2.7271132935811995,
      "grad_norm": 0.6425857543945312,
      "learning_rate": 1.820413889863206e-06,
      "loss": 0.3542,
      "step": 15550
    },
    {
      "epoch": 2.7358821466152228,
      "grad_norm": 0.3654736578464508,
      "learning_rate": 1.761954869636385e-06,
      "loss": 0.2024,
      "step": 15600
    },
    {
      "epoch": 2.744650999649246,
      "grad_norm": 209.98638916015625,
      "learning_rate": 1.703495849409564e-06,
      "loss": 0.3558,
      "step": 15650
    },
    {
      "epoch": 2.753419852683269,
      "grad_norm": 32.57550048828125,
      "learning_rate": 1.6450368291827431e-06,
      "loss": 0.2763,
      "step": 15700
    },
    {
      "epoch": 2.7621887057172922,
      "grad_norm": 0.416853129863739,
      "learning_rate": 1.586577808955922e-06,
      "loss": 0.1751,
      "step": 15750
    },
    {
      "epoch": 2.7709575587513156,
      "grad_norm": 96.70096588134766,
      "learning_rate": 1.528118788729101e-06,
      "loss": 0.3316,
      "step": 15800
    },
    {
      "epoch": 2.7797264117853384,
      "grad_norm": 0.13217350840568542,
      "learning_rate": 1.46965976850228e-06,
      "loss": 0.2856,
      "step": 15850
    },
    {
      "epoch": 2.7884952648193617,
      "grad_norm": 48.22751235961914,
      "learning_rate": 1.4112007482754588e-06,
      "loss": 0.3384,
      "step": 15900
    },
    {
      "epoch": 2.797264117853385,
      "grad_norm": 0.2502964735031128,
      "learning_rate": 1.352741728048638e-06,
      "loss": 0.3016,
      "step": 15950
    },
    {
      "epoch": 2.806032970887408,
      "grad_norm": 21.771961212158203,
      "learning_rate": 1.294282707821817e-06,
      "loss": 0.2989,
      "step": 16000
    },
    {
      "epoch": 2.814801823921431,
      "grad_norm": 28.784908294677734,
      "learning_rate": 1.235823687594996e-06,
      "loss": 0.1834,
      "step": 16050
    },
    {
      "epoch": 2.8235706769554545,
      "grad_norm": 0.22903861105442047,
      "learning_rate": 1.177364667368175e-06,
      "loss": 0.2678,
      "step": 16100
    },
    {
      "epoch": 2.8323395299894774,
      "grad_norm": 95.49362182617188,
      "learning_rate": 1.118905647141354e-06,
      "loss": 0.3244,
      "step": 16150
    },
    {
      "epoch": 2.8411083830235007,
      "grad_norm": 13.60848331451416,
      "learning_rate": 1.060446626914533e-06,
      "loss": 0.252,
      "step": 16200
    },
    {
      "epoch": 2.8498772360575235,
      "grad_norm": 99.01890563964844,
      "learning_rate": 1.001987606687712e-06,
      "loss": 0.2441,
      "step": 16250
    },
    {
      "epoch": 2.858646089091547,
      "grad_norm": 58.758827209472656,
      "learning_rate": 9.43528586460891e-07,
      "loss": 0.2578,
      "step": 16300
    },
    {
      "epoch": 2.86741494212557,
      "grad_norm": 8.93266487121582,
      "learning_rate": 8.8506956623407e-07,
      "loss": 0.3663,
      "step": 16350
    },
    {
      "epoch": 2.876183795159593,
      "grad_norm": 2.327561855316162,
      "learning_rate": 8.26610546007249e-07,
      "loss": 0.2835,
      "step": 16400
    },
    {
      "epoch": 2.8849526481936163,
      "grad_norm": 8.729909896850586,
      "learning_rate": 7.68151525780428e-07,
      "loss": 0.1881,
      "step": 16450
    },
    {
      "epoch": 2.893721501227639,
      "grad_norm": 66.08572387695312,
      "learning_rate": 7.09692505553607e-07,
      "loss": 0.2686,
      "step": 16500
    },
    {
      "epoch": 2.9024903542616625,
      "grad_norm": 13.044099807739258,
      "learning_rate": 6.51233485326786e-07,
      "loss": 0.2956,
      "step": 16550
    },
    {
      "epoch": 2.9112592072956858,
      "grad_norm": 4.90023946762085,
      "learning_rate": 5.92774465099965e-07,
      "loss": 0.2716,
      "step": 16600
    },
    {
      "epoch": 2.9200280603297086,
      "grad_norm": 0.03675791993737221,
      "learning_rate": 5.34315444873144e-07,
      "loss": 0.1929,
      "step": 16650
    },
    {
      "epoch": 2.928796913363732,
      "grad_norm": 0.8454079627990723,
      "learning_rate": 4.75856424646323e-07,
      "loss": 0.2347,
      "step": 16700
    },
    {
      "epoch": 2.9375657663977552,
      "grad_norm": 119.04876708984375,
      "learning_rate": 4.17397404419502e-07,
      "loss": 0.2185,
      "step": 16750
    },
    {
      "epoch": 2.946334619431778,
      "grad_norm": 89.03358459472656,
      "learning_rate": 3.589383841926809e-07,
      "loss": 0.2873,
      "step": 16800
    },
    {
      "epoch": 2.9551034724658014,
      "grad_norm": 47.82424545288086,
      "learning_rate": 3.0047936396586e-07,
      "loss": 0.3408,
      "step": 16850
    },
    {
      "epoch": 2.9638723254998247,
      "grad_norm": 1.4450503587722778,
      "learning_rate": 2.4202034373903897e-07,
      "loss": 0.218,
      "step": 16900
    },
    {
      "epoch": 2.9726411785338476,
      "grad_norm": 0.2645249664783478,
      "learning_rate": 1.8356132351221794e-07,
      "loss": 0.2962,
      "step": 16950
    },
    {
      "epoch": 2.981410031567871,
      "grad_norm": 73.19026947021484,
      "learning_rate": 1.2510230328539694e-07,
      "loss": 0.2497,
      "step": 17000
    },
    {
      "epoch": 2.990178884601894,
      "grad_norm": 89.07322692871094,
      "learning_rate": 6.664328305857595e-08,
      "loss": 0.2055,
      "step": 17050
    },
    {
      "epoch": 2.998947737635917,
      "grad_norm": 0.7863240242004395,
      "learning_rate": 8.18426283175494e-09,
      "loss": 0.2569,
      "step": 17100
    },
    {
      "epoch": 3.0,
      "eval_accuracy": 0.7885,
      "eval_f1_macro": 0.7804756623510355,
      "eval_loss": 0.9767364263534546,
      "eval_runtime": 70.6536,
      "eval_samples_per_second": 28.307,
      "eval_steps_per_second": 3.538,
      "step": 17106
    }
  ],
  "logging_steps": 50,
  "max_steps": 17106,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 2940357707571438.0,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
